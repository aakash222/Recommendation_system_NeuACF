# -*- coding: utf-8 -*-
"""ML_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IlTdvBeiPhdjNYUglYZly4nKJjiGPK_J
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F


PATH = "/home/smoke/Documents/Machine Learning/project/NeuACF/processed1/"

class NeuACF(nn.Module):
  def __init__(self, num_U, num_I):
    super(NeuACF, self).__init__()
    self.UIBIU = nn.Sequential(
        nn.Linear(num_U,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,64)
    )
    self.UIU = nn.Sequential(
        nn.Linear(num_U,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,64)
    )
    self.IBI = nn.Sequential(
        nn.Linear(num_I,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,64)
    )
    self.IUI = nn.Sequential(
        nn.Linear(num_I,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,600), nn.ReLU(),
        nn.Linear(600,64)
    )
    self.UIBIU_att = nn.Sequential(nn.Linear(64,16), nn.ReLU(), nn.Linear(16,1))
    self.UIU_att = nn.Sequential(nn.Linear(64,16), nn.ReLU(), nn.Linear(16,1))
    self.IBI_att = nn.Sequential(nn.Linear(64,16), nn.ReLU(), nn.Linear(16,1))
    self.IUI_att = nn.Sequential(nn.Linear(64,16), nn.ReLU(), nn.Linear(16,1))
    self.softmax_u = nn.Softmax(dim=1)
    self.softmax_i = nn.Softmax(dim=1)
    self.sigmoid = nn.Sigmoid()

  def forward(self,uibiu,uiu,ibi,iui):
    x_u_1 = self.UIBIU(uibiu).squeeze()
    x_u_2 = self.UIU(uiu).squeeze()
    myvar_u = torch.cat((self.UIBIU_att(x_u_1).squeeze().unsqueeze(1),self.UIU_att(x_u_2).squeeze().unsqueeze(1)),dim=1)
    scores_u = self.softmax_u(myvar_u)

    x_u_1 = x_u_1 * scores_u[:,0].view(x_u_1.shape[0],1)
    x_u_2 = x_u_2 * scores_u[:,1].view(x_u_1.shape[0],1)
    x_u = x_u_1 + x_u_2
    

    x_i_1 = self.IBI(ibi).squeeze()
    x_i_2 = self.IUI(iui).squeeze()
    myvar_i = torch.cat((self.IBI_att(x_i_1).squeeze().unsqueeze(1),self.IUI_att(x_i_2).squeeze().unsqueeze(1)),dim=1)
    scores_i = self.softmax_i(myvar_i)
    
    x_i_1 = x_i_1 * scores_i[:,0].view(x_i_1.shape[0],1)
    x_i_2 = x_i_2 * scores_i[:,1].view(x_i_1.shape[0],1)
    x_i = x_i_1 + x_i_2

    z = torch.bmm(x_u.view(x_u.shape[0], 1, 64), x_i.view(x_i.shape[0], 64, 1)).squeeze()
    z = self.sigmoid(z)
    return z

####### Give number of users and number of items
#num_U = 
#num_I =

ratings = np.genfromtxt(PATH+"ratings_reduced.txt",delimiter=' ')
uibiu = np.genfromtxt(PATH+"similarities/UICIU.csv",delimiter=',')
uiu = np.genfromtxt(PATH+"similarities/UIU.csv",delimiter=',')
iui = np.genfromtxt(PATH+"similarities/IUI.csv",delimiter=',')
ibi = np.genfromtxt(PATH+"similarities/ICI.csv",delimiter=',')
rat_mat = np.genfromtxt(PATH+"UI_new.csv",delimiter=',')



num_items = int(max(ratings[:,1])+1)
num_users = int(max(ratings[:,0])+1)
print("number of items: ",num_items)
print("number of users: ",num_users)
train_ratings = list()
for i in ratings:
  train_ratings.append([i[0], i[1], 1])
print("positive samples: ",len(train_ratings))
##### negative sampling
negative_samples = list()
negative_sampling_ratio = 10
for i in range(len(ratings)):
  for neg in range(negative_sampling_ratio):
    j = np.random.randint(num_items)
    while rat_mat[int(ratings[i,0])][j] != 0:
      j = np.random.randint(num_items)
    train_ratings.append([ratings[i][0], j, 0])

print("total samples: ",len(train_ratings))
train_ratings = np.array(train_ratings, dtype=int)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
epochs = 4
batch_size = 128
learning_rate = .0005
net = NeuACF(num_users, num_items).float().to(device)
criterion = nn.BCELoss()
optimizer = optim.Adam(net.parameters(), lr=learning_rate)

####### training ##############
for epoch in range(epochs):
  c = 0
  l = 0
  np.random.shuffle(train_ratings)
  for batch in range(len(train_ratings)//batch_size):
    u_id = train_ratings[(batch*batch_size):(batch*batch_size)+batch_size,0]
    i_id = train_ratings[(batch*batch_size):(batch*batch_size)+batch_size,1]

    uibiu_data = list()
    for i in u_id:
      uibiu_data.append(uibiu[i])

    uiu_data = list()
    for i in u_id:
      uiu_data.append(uiu[i])

    iui_data = list()
    for i in i_id:
      iui_data.append(iui[i])

    ibi_data = list()
    for i in i_id:
      ibi_data.append(ibi[i])

    uibiu_data = torch.tensor(uibiu_data,dtype=torch.float).view(batch_size,num_users).unsqueeze(1).unsqueeze(1).to(device)
    uiu_data = torch.tensor(uiu_data,dtype=torch.float).view(batch_size,num_users).unsqueeze(1).unsqueeze(1).to(device)
    iui_data = torch.tensor(iui_data,dtype=torch.float).view(batch_size,num_items).unsqueeze(1).unsqueeze(1).to(device)
    ibi_data = torch.tensor(ibi_data,dtype=torch.float).view(batch_size,num_items).unsqueeze(1).unsqueeze(1).to(device)
    y = torch.tensor(train_ratings[(batch*batch_size):(batch*batch_size)+batch_size,2],dtype=torch.float).to(device)

    optimizer.zero_grad()
    out = net(uibiu_data,uiu_data,ibi_data,iui_data)
    loss = criterion(out,y)
    loss.backward()
    optimizer.step()
    l+=loss

    c+=1
    if c%10 == 0:
      print("epoch: "+str(epoch)+" batch: "+str(c)+" loss: "+str(l))
      l = 0
    if c%100 == 0:
      torch.save(net.state_dict(),PATH+"net_cat.pt")
